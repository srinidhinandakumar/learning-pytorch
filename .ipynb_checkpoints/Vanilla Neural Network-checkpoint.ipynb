{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_activation(z):\n",
    "    return 1/(1+math.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectified linear units = max(0,x)\n",
    "\n",
    "Different types:-\n",
    "- Simple ReLU : max(0,x)\n",
    "- Leaky ReLU : \n",
    "  - f(x) = x x>0\n",
    "  - f(x) = 0.01x otherwise\n",
    "- Noisy ReLU : max (0, x+Y) where Y ~ N(0,sigma(x)) [N: Guassian Noise] \n",
    "- Parametric ReLU : \n",
    "  - [a>1]\n",
    "  \n",
    "     f(x) = x x>0\n",
    "     \n",
    "     f(x) = ax otherwise\n",
    "     \n",
    "  - [a<=1]\n",
    "  \n",
    "     max(x,ax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return max(0,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softplus(z):\n",
    "    # softplus function = log(1+exp(x)) -> smooth approximation of relu that can be differentiated\n",
    "    return math.log(1+math.exp(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh (Hyperbolic function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    return (math.exp(z)-math.exp(-z))/(math.exp(z)+math.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_sigmoid(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = sigmoid_activation(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_relu(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = relu(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_softplus(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = softplus(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_tanh(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = tanh(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(y):\n",
    "    if y>0.5:\n",
    "        # print(\"Stairs\")\n",
    "        return 1\n",
    "    else:\n",
    "        # print(\"Not Stairs\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_sigmoid(x):\n",
    "    y_left = neuron_sigmoid(x, w_1, b_left)\n",
    "    y_right = neuron_sigmoid(x, w_2, b_right)\n",
    "    y_exp = neuron_sigmoid([y_left, y_right], [w_left, w_right], b)\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_relu(x):\n",
    "    y_left = neuron_relu(x, w_1, b_left)\n",
    "    y_right = neuron_relu(x, w_2, b_right)\n",
    "    y_exp = neuron_relu([y_left, y_right], [w_left, w_right], b)\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_softplus(x):\n",
    "    y_left = neuron_softplus(x, w_1, b_left)\n",
    "    y_right = neuron_softplus(x, w_2, b_right)\n",
    "    y_exp = neuron_softplus([y_left, y_right], [w_left, w_right], b)\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_tanh(x):\n",
    "    y_left = neuron_tanh(x, w_1, b_left)\n",
    "    y_right = neuron_tanh(x, w_2, b_right)\n",
    "    y_exp = neuron_tanh([y_left, y_right], [w_left, w_right], b)\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = [0.002, -0.050, 0.012, 0.012]\n",
    "w_2 = [-0.05, 0.002, 0.012, 0.012]\n",
    "w_left = 3\n",
    "w_right = 3\n",
    "b_left = -0.5\n",
    "b_right = -0.5\n",
    "b = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = [115, 130, 80, 88]\n",
    "x2 = [47, 250, 8, 88]\n",
    "x3 = [182, 5, 157, 155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction,val = stairs_sigmoid(x1)\n",
    "print(prediction)\n",
    "prediction,val = stairs_relu(x1)\n",
    "print(prediction)\n",
    "prediction,val = stairs_softplus(x1)\n",
    "print(prediction)\n",
    "prediction,val = stairs_tanh(x1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction,val = stairs_sigmoid(x2)\n",
    "print(prediction)\n",
    "prediction,val = stairs_relu(x2)\n",
    "print(prediction)\n",
    "prediction,val = stairs_softplus(x2)\n",
    "print(prediction)\n",
    "prediction,val = stairs_tanh(x2)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "1\n",
      "1\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "prediction,val = stairs_sigmoid(x3)\n",
    "print(prediction)\n",
    "prediction,val = stairs_relu(x3)\n",
    "print(prediction)\n",
    "prediction,val = stairs_softplus(x3)\n",
    "print(prediction)\n",
    "prediction,val = stairs_tanh(x3)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Neural Network to fit training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata = open(\"train.csv\").read().split(\"\\n\")[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    preprocessed_data = dict()\n",
    "    for d in data:\n",
    "        line = d.split(\",\")\n",
    "        preprocessed_data[line[0]] = dict()\n",
    "        preprocessed_data[line[0]][\"y\"] = int(line[-1])# label\n",
    "        preprocessed_data[line[0]][\"x\"] = [int(line[1]),int(line[2]),int(line[3]),int(line[4])]\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessed = preprocess(traindata[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial assumption - random weights and bias\n",
    "w_1 = [0.002, -0.050, 0.012, 0.012]\n",
    "w_2 = [-0.05, 0.002, 0.012, 0.012]\n",
    "w_left = 3\n",
    "w_right = 3\n",
    "b_left = -0.5\n",
    "b_right = -0.5\n",
    "b = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit():\n",
    "    for i in preprocessed:\n",
    "        #print(i)\n",
    "        y_exp, val = stairs_sigmoid(preprocessed[i][\"x\"])\n",
    "        preprocessed[i][\"y-exp\"] = y_exp\n",
    "        preprocessed[i][\"neuron-op\"] = val\n",
    "    pprint.pprint(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function Mean Squared Error\n",
    "def mse_predictor(data):\n",
    "    mse_sum = 0\n",
    "    n = len(data)\n",
    "    for item in data:\n",
    "        mse_sum += math.pow((data[item][\"y-exp\"]-data[item][\"y\"]),2) # observed - true \n",
    "    print (mse_sum/n)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'neuron-op': 0.8735069706949717,\n",
      "       'x': [252, 4, 155, 175],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '2': {'neuron-op': 0.8781464903610091,\n",
      "       'x': [175, 10, 186, 200],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '3': {'neuron-op': 0.5920575066543718,\n",
      "       'x': [82, 131, 230, 100],\n",
      "       'y': 0,\n",
      "       'y-exp': 1},\n",
      " '4': {'neuron-op': 0.2836270003389756,\n",
      "       'x': [115, 138, 80, 88],\n",
      "       'y': 0,\n",
      "       'y-exp': 0},\n",
      " '5': {'neuron-op': 0.9885624404114893,\n",
      "       'x': [27, 60, 194, 238],\n",
      "       'y': 0,\n",
      "       'y-exp': 1}}\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "mse_predictor(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to observe change in weights and it's effect on mse\n",
    "w_1 = [0.002, -0.050, 0.012, 0.012] \n",
    "w_2 = [-0.05, -1, 0.05, 0.012] # change 2nd weight\n",
    "w_left = 3\n",
    "w_right = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'neuron-op': 0.8737062310734811,\n",
      "       'x': [252, 4, 155, 175],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '2': {'neuron-op': 0.8750816380298204,\n",
      "       'x': [175, 10, 186, 200],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '3': {'neuron-op': 0.29998893813188676,\n",
      "       'x': [82, 131, 230, 100],\n",
      "       'y': 0,\n",
      "       'y-exp': 0},\n",
      " '4': {'neuron-op': 0.2723423503744277,\n",
      "       'x': [115, 138, 80, 88],\n",
      "       'y': 0,\n",
      "       'y-exp': 0},\n",
      " '5': {'neuron-op': 0.8251012037127704,\n",
      "       'x': [27, 60, 194, 238],\n",
      "       'y': 0,\n",
      "       'y-exp': 1}}\n",
      "0.2\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "mse_predictor(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = [0.002, -1, 0.012, 0.012] # change 2nd weight\n",
    "w_2 = [-0.05, 0.002, 0.05, 0.012] \n",
    "w_left = 3\n",
    "w_right = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'neuron-op': 0.6424121898483348,\n",
      "       'x': [252, 4, 155, 175],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '2': {'neuron-op': 0.8554532866768318,\n",
      "       'x': [175, 10, 186, 200],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '3': {'neuron-op': 0.8807235033641981,\n",
      "       'x': [82, 131, 230, 100],\n",
      "       'y': 0,\n",
      "       'y-exp': 1},\n",
      " '4': {'neuron-op': 0.4640861418704272,\n",
      "       'x': [115, 138, 80, 88],\n",
      "       'y': 0,\n",
      "       'y-exp': 0},\n",
      " '5': {'neuron-op': 0.8807908174177795,\n",
      "       'x': [27, 60, 194, 238],\n",
      "       'y': 0,\n",
      "       'y-exp': 1}}\n",
      "0.4\n"
     ]
    }
   ],
   "source": [
    "fit()\n",
    "mse_predictor(preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives of Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_sigmoid(z):\n",
    "    return z*(1-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def derivative_relu(z):\n",
    "    if z>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 # ReLU is undefined at z = 0 but here it's taken 0 for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_softplus(z):\n",
    "    return (math.exp(z) - 1)/math.exp(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_tanh(z):\n",
    "    return 1 - math.pow(z,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprobagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backprob_error_sigmoid(data):\n",
    "    # print(data)\n",
    "    for item in data:\n",
    "        data[item][\"backprob-error\"] = (data[item][\"y\"] - data[item][\"y-exp\"])*derivative_sigmoid(data[item][\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob_error_relu(data):\n",
    "    for item in data:\n",
    "        data[item][\"backprob-error\"] = (data[item][\"y\"] - data[item][\"y-exp\"])*derivative_relu(data[item][\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob_error_softplus(data):\n",
    "    for item in data:\n",
    "        data[item][\"backprob-error\"] = (data[item][\"y\"] - data[item][\"y-exp\"])*derivative_softplus(data[item][\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob_error_tanh(data):\n",
    "    for item in data:\n",
    "        data[item][\"backprob-error\"] = (data[item][\"y\"] - data[item][\"y-exp\"])*derivative_tanh(data[item][\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'backprob-error': 0.0,\n",
      "       'neuron-op': 0.6424121898483348,\n",
      "       'x': [252, 4, 155, 175],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '2': {'backprob-error': 0.0,\n",
      "       'neuron-op': 0.8554532866768318,\n",
      "       'x': [175, 10, 186, 200],\n",
      "       'y': 1,\n",
      "       'y-exp': 1},\n",
      " '3': {'backprob-error': -0.10504961398609142,\n",
      "       'neuron-op': 0.8807235033641981,\n",
      "       'x': [82, 131, 230, 100],\n",
      "       'y': 0,\n",
      "       'y-exp': 1},\n",
      " '4': {'backprob-error': 0.0,\n",
      "       'neuron-op': 0.4640861418704272,\n",
      "       'x': [115, 138, 80, 88],\n",
      "       'y': 0,\n",
      "       'y-exp': 0},\n",
      " '5': {'backprob-error': -0.1049983533702993,\n",
      "       'neuron-op': 0.8807908174177795,\n",
      "       'x': [27, 60, 194, 238],\n",
      "       'y': 0,\n",
      "       'y-exp': 1}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(backprob_error_sigmoid(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_weights(weights,l_rate,data):\n",
    "    new_weights = []\n",
    "    for weight,x in zip(weights, data[\"x\"]):\n",
    "        w_error = weight*data[\"backprob-error\"]*derivative_sigmoid(data[\"neuron-op\"])\n",
    "        w = weight+w_error*l_rate*x\n",
    "        new_weights.append(w)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(network, data, n_epochs, l_rate):\n",
    "    items = list(reversed(list(data.keys())))\n",
    "    for epoch in range(n_epochs):\n",
    "        for item in items:\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5', '4', '3', '2', '1']"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(reversed(list(preprocessed.keys())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.002, -1, 0.012, 0.012]\n",
      "5\n",
      "[0.0017023343363171957, -0.6692603736857727, -0.000832697500992019, -0.0037432062125572173]\n",
      "[0.0017023343363171957, -0.6692603736857727, -0.000832697500992019, -0.0037432062125572173]\n",
      "4\n",
      "[0.0017023343363171957, -0.6692603736857727, -0.000832697500992019, -0.0037432062125572173]\n",
      "[0.0017023343363171957, -0.6692603736857727, -0.000832697500992019, -0.0037432062125572173]\n",
      "3\n",
      "[0.0009321092890501055, -0.18550552237463824, 0.00022405679842647688, -0.00167781331568088]\n",
      "[0.0009321092890501055, -0.18550552237463824, 0.00022405679842647688, -0.00167781331568088]\n",
      "2\n",
      "[0.0009321092890501055, -0.18550552237463824, 0.00022405679842647688, -0.00167781331568088]\n",
      "[0.0009321092890501055, -0.18550552237463824, 0.00022405679842647688, -0.00167781331568088]\n",
      "1\n",
      "[0.0009321092890501055, -0.18550552237463824, 0.00022405679842647688, -0.00167781331568088]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0009321092890501055,\n",
       " -0.18550552237463824,\n",
       " 0.00022405679842647688,\n",
       " -0.00167781331568088]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print(w_1)\n",
    "update_weights(w_1, 0.5, preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
