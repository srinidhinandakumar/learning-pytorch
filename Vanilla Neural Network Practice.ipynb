{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Activation Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid_activation(z):\n",
    "    return 1/(1+math.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rectified linear units = max(0,x)\n",
    "\n",
    "Different types:-\n",
    "- Simple ReLU : max(0,x)\n",
    "- Leaky ReLU : \n",
    "  - f(x) = x x>0\n",
    "  - f(x) = 0.01x otherwise\n",
    "- Noisy ReLU : max (0, x+Y) where Y ~ N(0,sigma(x)) [N: Guassian Noise] \n",
    "- Parametric ReLU : \n",
    "  - [a>1]\n",
    "  \n",
    "     f(x) = x x>0\n",
    "     \n",
    "     f(x) = ax otherwise\n",
    "     \n",
    "  - [a<=1]\n",
    "  \n",
    "     max(x,ax)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def relu(z):\n",
    "    return max(0,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Softplus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def softplus(z):\n",
    "    # softplus function = log(1+exp(x)) -> smooth approximation of relu that can be differentiated\n",
    "    return math.log(1+math.exp(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tanh (Hyperbolic function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tanh(z):\n",
    "    return (math.exp(z)-math.exp(-z))/(math.exp(z)+math.exp(-z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neurons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_sigmoid(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = sigmoid_activation(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_relu(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = relu(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_softplus(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = softplus(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def neuron_tanh(x,w,b):\n",
    "    z=0\n",
    "    for x_,w_ in zip(x,w):\n",
    "        z+=x_*w_\n",
    "    z+=b\n",
    "    y = tanh(z)\n",
    "    return y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def predict(y):\n",
    "    if y>0.5:\n",
    "        # print(\"Stairs\")\n",
    "        return 1\n",
    "    else:\n",
    "        # print(\"Not Stairs\")\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_sigmoid(network, x):\n",
    "    y_left = neuron_sigmoid(x, network[\"w_1\"], network[\"b_left\"])\n",
    "    y_right = neuron_sigmoid(x, network[\"w_2\"], network[\"b_right\"])\n",
    "    y_exp = neuron_sigmoid([y_left, y_right], [network[\"w_left\"], network[\"w_right\"]], network[\"b\"])\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_relu(x):\n",
    "    y_left = neuron_relu(x, w_1, b_left)\n",
    "    y_right = neuron_relu(x, w_2, b_right)\n",
    "    y_exp = neuron_relu([y_left, y_right], [w_left, w_right], b)\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_softplus(x):\n",
    "    y_left = neuron_softplus(x, w_1, b_left)\n",
    "    y_right = neuron_softplus(x, w_2, b_right)\n",
    "    y_exp = neuron_softplus([y_left, y_right], [w_left, w_right], b)\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def stairs_tanh(x):\n",
    "    y_left = neuron_tanh(x, w_1, b_left)\n",
    "    y_right = neuron_tanh(x, w_2, b_right)\n",
    "    y_exp = neuron_tanh([y_left, y_right], [w_left, w_right], b)\n",
    "    return predict(y_exp),y_exp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = [0.002, -0.050, 0.012, 0.012]\n",
    "w_2 = [-0.05, 0.002, 0.012, 0.012]\n",
    "w_left = 3\n",
    "w_right = 3\n",
    "b_left = -0.5\n",
    "b_right = -0.5\n",
    "b = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x1 = [115, 130, 80, 88]\n",
    "x2 = [47, 250, 8, 88]\n",
    "x3 = [182, 5, 157, 155]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction,val = stairs_sigmoid(x1)\n",
    "print(prediction)\n",
    "prediction,val = stairs_relu(x1)\n",
    "print(prediction)\n",
    "prediction,val = stairs_softplus(x1)\n",
    "print(prediction)\n",
    "prediction,val = stairs_tanh(x1)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction,val = stairs_sigmoid(x2)\n",
    "print(prediction)\n",
    "prediction,val = stairs_relu(x2)\n",
    "print(prediction)\n",
    "prediction,val = stairs_softplus(x2)\n",
    "print(prediction)\n",
    "prediction,val = stairs_tanh(x2)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "prediction,val = stairs_sigmoid(x3)\n",
    "print(prediction)\n",
    "prediction,val = stairs_relu(x3)\n",
    "print(prediction)\n",
    "prediction,val = stairs_softplus(x3)\n",
    "print(prediction)\n",
    "prediction,val = stairs_tanh(x3)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vanilla Neural Network to fit training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "traindata = open(\"train.csv\").read().split(\"\\n\")[1:] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    preprocessed_data = dict()\n",
    "    for d in data:\n",
    "        line = d.split(\",\")\n",
    "        preprocessed_data[line[0]] = dict()\n",
    "        preprocessed_data[line[0]][\"y\"] = int(line[-1])# label\n",
    "        preprocessed_data[line[0]][\"x\"] = [int(line[1]),int(line[2]),int(line[3]),int(line[4])]\n",
    "    return preprocessed_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "preprocessed = preprocess(traindata[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'1': {'x': [252, 4, 155, 175], 'y': 1},\n",
      " '2': {'x': [175, 10, 186, 200], 'y': 1},\n",
      " '3': {'x': [82, 131, 230, 100], 'y': 0},\n",
      " '4': {'x': [115, 138, 80, 88], 'y': 0},\n",
      " '5': {'x': [27, 60, 194, 238], 'y': 0}}\n"
     ]
    }
   ],
   "source": [
    "pprint.pprint(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initial assumption - random weights and bias\n",
    "w_1 = [0.002, -0.050, 0.012, 0.012]\n",
    "w_2 = [-0.05, 0.002, 0.012, 0.012]\n",
    "w_left = 3\n",
    "w_right = 3\n",
    "b_left = -0.5\n",
    "b_right = -0.5\n",
    "b = -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forward_propagate(network, data):\n",
    "    y_exp, val = stairs_sigmoid(network, data[\"x\"])\n",
    "    data[\"y-exp\"] = y_exp\n",
    "    data[\"neuron-op\"] = val\n",
    "    pprint.pprint(data)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# loss function Squared Error\n",
    "def mse_predictor(data):\n",
    "    mse_sum = 0\n",
    "    n = len(data)\n",
    "    for item in data:\n",
    "        mse_sum += math.pow((data[item][\"y-exp\"]-data[item][\"y\"]),2) # observed - true \n",
    "    print (mse_sum/n)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit()\n",
    "mse_predictor(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# to observe change in weights and it's effect on mse\n",
    "w_1 = [0.002, -0.050, 0.012, 0.012] \n",
    "w_2 = [-0.05, -1, 0.05, 0.012] # change 2nd weight\n",
    "w_left = 3\n",
    "w_right = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit()\n",
    "mse_predictor(preprocessed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "w_1 = [0.002, -1, 0.012, 0.012] # change 2nd weight\n",
    "w_2 = [-0.05, 0.002, 0.05, 0.012] \n",
    "w_left = 3\n",
    "w_right = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fit()\n",
    "mse_predictor(preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Derivatives of Activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_sigmoid(z):\n",
    "    return z*(1-z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_relu(z):\n",
    "    if z>0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0 # ReLU is undefined at z = 0 but here it's taken 0 for simplicity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_softplus(z):\n",
    "    return (math.exp(z) - 1)/math.exp(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def derivative_tanh(z):\n",
    "    return 1 - math.pow(z,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backprobagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob_error_sigmoid(data):\n",
    "    data[\"backprob-error\"] = (data[\"y\"] - data[\"y-exp\"])*derivative_sigmoid(data[\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob_error_relu(data):\n",
    "    for item in data:\n",
    "        data[item][\"backprob-error\"] = (data[item][\"y\"] - data[item][\"y-exp\"])*derivative_relu(data[item][\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob_error_softplus(data):\n",
    "    for item in data:\n",
    "        data[item][\"backprob-error\"] = (data[item][\"y\"] - data[item][\"y-exp\"])*derivative_softplus(data[item][\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def backprob_error_tanh(data):\n",
    "    for item in data:\n",
    "        data[item][\"backprob-error\"] = (data[item][\"y\"] - data[item][\"y-exp\"])*derivative_tanh(data[item][\"neuron-op\"])\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pprint.pprint(backprob_error_sigmoid(preprocessed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_weights(weights,l_rate,data):\n",
    "    new_weights = []\n",
    "    for weight,x in zip(weights, data[\"x\"]):\n",
    "        w_error = weight*data[\"backprob-error\"]*derivative_sigmoid(data[\"neuron-op\"])\n",
    "        w = weight+w_error*l_rate*x\n",
    "        new_weights.append(w)\n",
    "    return new_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(network, data, n_epochs, l_rate):\n",
    "    items = list(reversed(list(data.keys())))\n",
    "    for epoch in range(n_epochs):\n",
    "        sum_error = 0\n",
    "        for item in items:\n",
    "            data[item] = forward_propagate(network, data[item])\n",
    "            data[item] = backprob_error_sigmoid(data[item])\n",
    "            sum_error+=math.pow((data[item][\"y-exp\"]-data[item][\"y\"]),2)\n",
    "            network[\"w_1\"] = update_weights(network[\"w_1\"],l_rate,data[item])\n",
    "            #print(\"Weights Left: \",str(network[\"w_1\"]))\n",
    "            network[\"w_2\"] = update_weights(network[\"w_2\"],l_rate,data[item])\n",
    "            #print(\"Weights Right: \",str(network[\"w_2\"]))\n",
    "        print(\"epoch = %d error = %0.5f learning rate = %f\"%(epoch, sum_error, l_rate))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'neuron-op': 0.9885624404114893, 'x': [27, 60, 194, 238], 'y': 0, 'y-exp': 1}\n",
      "Weights Left:  [0.001996548254914735, -0.04980823638415195, 0.011851191434101915, 0.011817441037712657]\n",
      "Weights Right:  [-0.04991370637286838, 0.001992329455366078, 0.011851191434101915, 0.011817441037712657]\n",
      "{'neuron-op': 0.28340821222653634, 'x': [115, 138, 80, 88], 'y': 0, 'y-exp': 0}\n",
      "Weights Left:  [0.001996548254914735, -0.04980823638415195, 0.011851191434101915, 0.011817441037712657]\n",
      "Weights Right:  [-0.04991370637286838, 0.001992329455366078, 0.011851191434101915, 0.011817441037712657]\n",
      "{'neuron-op': 0.5829946959241128, 'x': [82, 131, 230, 100], 'y': 0, 'y-exp': 1}\n",
      "Weights Left:  [-0.0028415650283638762, 0.1430129850453361, -0.06870004644905899, -0.023105098166819077]\n",
      "Weights Right:  [0.07103912570909691, -0.005720519401813442, -0.06870004644905899, -0.023105098166819077]\n",
      "{'neuron-op': 0.2712905253066391, 'x': [175, 10, 186, 200], 'y': 1, 'y-exp': 0}\n",
      "Weights Left:  [-0.012558823118676057, 0.1709592364360786, -0.31839977186232726, -0.11340471418742284]\n",
      "Weights Right:  [0.3139705779669014, -0.006838369457443143, -0.31839977186232726, -0.11340471418742284]\n",
      "{'neuron-op': 0.880770902157354, 'x': [252, 4, 155, 175], 'y': 1, 'y-exp': 1}\n",
      "Weights Left:  [-0.012558823118676057, 0.1709592364360786, -0.31839977186232726, -0.11340471418742284]\n",
      "Weights Right:  [0.3139705779669014, -0.006838369457443143, -0.31839977186232726, -0.11340471418742284]\n",
      "epoch = 0 error = 3.00000 learning rate = 0.500000\n",
      "{'backprob-error': -0.011306741819169939,\n",
      " 'neuron-op': 0.2689414213699951,\n",
      " 'x': [27, 60, 194, 238],\n",
      " 'y': 0,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.012558823118676057, 0.1709592364360786, -0.31839977186232726, -0.11340471418742284]\n",
      "Weights Right:  [0.3139705779669014, -0.006838369457443143, -0.31839977186232726, -0.11340471418742284]\n",
      "{'backprob-error': 0.0,\n",
      " 'neuron-op': 0.48434579071111894,\n",
      " 'x': [115, 138, 80, 88],\n",
      " 'y': 0,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.012558823118676057, 0.1709592364360786, -0.31839977186232726, -0.11340471418742284]\n",
      "Weights Right:  [0.3139705779669014, -0.006838369457443143, -0.31839977186232726, -0.11340471418742284]\n",
      "{'backprob-error': -0.24311188044846405,\n",
      " 'neuron-op': 0.2689414213699951,\n",
      " 'x': [82, 131, 230, 100],\n",
      " 'y': 0,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.012558823118676057, 0.1709592364360786, -0.31839977186232726, -0.11340471418742284]\n",
      "Weights Right:  [0.3139705779669014, -0.006838369457443143, -0.31839977186232726, -0.11340471418742284]\n",
      "{'backprob-error': 0.19769197618548692,\n",
      " 'neuron-op': 0.26894142137064975,\n",
      " 'x': [175, 10, 186, 200],\n",
      " 'y': 1,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.05503806367939152, 0.2040024533135985, -1.4630569696008255, -0.5517848384726953]\n",
      "Weights Right:  [1.375951591984788, -0.008160098132543939, -1.4630569696008255, -0.5517848384726953]\n",
      "{'backprob-error': 0.0,\n",
      " 'neuron-op': 0.8807970779411083,\n",
      " 'x': [252, 4, 155, 175],\n",
      " 'y': 1,\n",
      " 'y-exp': 1}\n",
      "Weights Left:  [-0.05503806367939152, 0.2040024533135985, -1.4630569696008255, -0.5517848384726953]\n",
      "Weights Right:  [1.375951591984788, -0.008160098132543939, -1.4630569696008255, -0.5517848384726953]\n",
      "epoch = 1 error = 1.00000 learning rate = 0.500000\n",
      "{'backprob-error': 0.0,\n",
      " 'neuron-op': 0.2689414213699951,\n",
      " 'x': [27, 60, 194, 238],\n",
      " 'y': 0,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.05503806367939152, 0.2040024533135985, -1.4630569696008255, -0.5517848384726953]\n",
      "Weights Right:  [1.375951591984788, -0.008160098132543939, -1.4630569696008255, -0.5517848384726953]\n",
      "{'backprob-error': 0.0,\n",
      " 'neuron-op': 0.2690147006227181,\n",
      " 'x': [115, 138, 80, 88],\n",
      " 'y': 0,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.05503806367939152, 0.2040024533135985, -1.4630569696008255, -0.5517848384726953]\n",
      "Weights Right:  [1.375951591984788, -0.008160098132543939, -1.4630569696008255, -0.5517848384726953]\n",
      "{'backprob-error': 0.0,\n",
      " 'neuron-op': 0.2689414213699951,\n",
      " 'x': [82, 131, 230, 100],\n",
      " 'y': 0,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.05503806367939152, 0.2040024533135985, -1.4630569696008255, -0.5517848384726953]\n",
      "Weights Right:  [1.375951591984788, -0.008160098132543939, -1.4630569696008255, -0.5517848384726953]\n",
      "{'backprob-error': 0.19661193324178436,\n",
      " 'neuron-op': 0.2689414213699951,\n",
      " 'x': [175, 10, 186, 200],\n",
      " 'y': 1,\n",
      " 'y-exp': 0}\n",
      "Weights Left:  [-0.24120002526868115, 0.24343230483195757, -6.7227928078351225, -2.6847782312153736]\n",
      "Weights Right:  [6.030000631717028, -0.009737292193278301, -6.7227928078351225, -2.6847782312153736]\n"
     ]
    },
    {
     "ename": "OverflowError",
     "evalue": "math range error",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-a4f6b890cb73>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b_right\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreprocessed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-18-0b5c7ba282bf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(network, data, n_epochs, l_rate)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0msum_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mitem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mitems\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m             \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackprob_error_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m             \u001b[0msum_error\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y-exp\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-83119053a49d>\u001b[0m in \u001b[0;36mforward_propagate\u001b[0;34m(network, data)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mforward_propagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_exp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstairs_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"x\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"y-exp\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my_exp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"neuron-op\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mpprint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-5-ab3b5fae993e>\u001b[0m in \u001b[0;36mstairs_sigmoid\u001b[0;34m(network, x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mstairs_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_left\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w_1\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b_left\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0my_right\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w_2\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b_right\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0my_exp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mneuron_sigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0my_left\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_right\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w_left\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"w_right\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"b\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_exp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_exp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-3-6ff451805180>\u001b[0m in \u001b[0;36mneuron_sigmoid\u001b[0;34m(x, w, b)\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mz\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mx_\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mw_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mz\u001b[0m\u001b[0;34m+=\u001b[0m\u001b[0mb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msigmoid_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-2-8430e6bf4f9c>\u001b[0m in \u001b[0;36msigmoid_activation\u001b[0;34m(z)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msigmoid_activation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOverflowError\u001b[0m: math range error"
     ]
    }
   ],
   "source": [
    "# random initialization of network\n",
    "network = dict()\n",
    "network[\"w_1\"] = [0.002, -0.050, 0.012, 0.012]\n",
    "network[\"w_2\"] = [-0.05, 0.002, 0.012, 0.012]\n",
    "network[\"w_left\"] = 3\n",
    "network[\"w_right\"] = 3\n",
    "network[\"b_left\"] = -0.5\n",
    "network[\"b_right\"] = -0.5\n",
    "network[\"b\"] = -1\n",
    "train(network, preprocessed, 10, 0.5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
